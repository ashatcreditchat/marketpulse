{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2TokenizerFast\n",
    "import torch\n",
    "import hopsworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_csv(file_path, file_name='sentiment.csv'):\n",
    "    sentiment_map = {\"negative\": 0, \"positive\": 1, \"neutral\": 2}\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r', encoding=\"latin1\") as file:\n",
    "        for line in file:\n",
    "            sentence, sentiment = line.split(\"@\")\n",
    "            sentiment = sentiment.strip()  # remove any trailing whitespace\n",
    "            data.append([sentence, sentiment_map[sentiment]])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
    "    df.to_csv(file_name, index=False, sep=',')\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def get_embedding(dataset, embedding_object):\n",
    "    embeddings = []\n",
    "    for data in dataset[\"text\"]:\n",
    "        embedded_text = embedding_object.encode(data)\n",
    "        embeddings.append(embedded_text)\n",
    "\n",
    "    dataset_embedded = dataset.copy()\n",
    "    dataset_embedded[\"embeddings\"] = embeddings\n",
    "    dataset_embedded = dataset_embedded.drop(columns=[\"text\"])\n",
    "    return dataset_embedded\n",
    "\n",
    "def get_decoding(dataset, embedding_object):\n",
    "    decodings = []\n",
    "    for data in dataset[\"embeddings\"]:\n",
    "        decoded_text = embedding_object.decode(data)\n",
    "        decodings.append(decoded_text)\n",
    "\n",
    "    dataset_decoded = dataset.copy()\n",
    "    dataset_decoded[\"text\"] = decodings\n",
    "    dataset_decoded = dataset_decoded.drop(columns=[\"embeddings\"])\n",
    "    return dataset_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_phrase_bank_df = load_data(os.path.join(\"base-data\", \"FinancialPhraseBank\", \"all-data-75-above.csv\"))\n",
    "zeroshot_train_df = load_data(os.path.join(\"base-data\", \"twitter-financial-news-sentiment\", \"sent_train.csv\"))\n",
    "zeroshot_test_df = load_data(os.path.join(\"base-data\", \"twitter-financial-news-sentiment\", \"sent_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained('Xenova/text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_financial_phrase_bank_df = get_embedding(financial_phrase_bank_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_financial_phrase_bank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopsworks_project = hopsworks.login() \n",
    "fs = hopsworks_project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fg = fs.get_or_create_feature_group(name=\"test\", version=1, description=\"test\", primary_key=[\"label\", \"embeddings\"], online_enabled=True)\n",
    "embedding_fg.insert(embedded_financial_phrase_bank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = hopsworks.hsfs.connection()\n",
    "fs = connection.get_feature_store(name=\"id2223labs_featurestore\")\n",
    "fg = fs.get_feature_group('test', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fg.select([\"embeddings\", \"label\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = get_decoding(temp, tokenizer)\n",
    "print(decoded[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news-sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
